{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SQL-Fundamentals-Farsi**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<section style=\"direction: ltr; text-align: justify; margin: 30px;\">\n",
    "\n",
    "### Project Introduction\n",
    "\n",
    "This project is aimed at developing an automated reporting tool that facilitates accessing data from SQL Server databases, executing SQL queries, and exporting the resulting data into structured reports. The tool allows users to extract data and save it in both Excel and CSV formats, providing flexibility in data handling and storage. This functionality is particularly beneficial in data-driven environments where efficient reporting and data management are critical.\n",
    "\n",
    "### General Workflow of the Project\n",
    "\n",
    "1. **Database Connection**: \n",
    "   The first step in the process involves establishing a connection to the SQL Server database. This is done using the `SQLAlchemy` library, which provides a robust interface for interacting with relational databases. The connection can be made with or without login credentials, allowing flexibility in different authentication environments (SQL or Windows authentication).\n",
    "\n",
    "2. **Executing SQL Queries**:\n",
    "   After establishing a connection, users can execute their desired SQL queries to retrieve data from the database. These queries can include filtering, sorting, or aggregating data as per business needs. The tool then fetches the data into a Pandas DataFrame, which makes it easier to manipulate and display the results.\n",
    "\n",
    "3. **Data Display**:\n",
    "   The retrieved data is displayed in the console in a tabular format. Users can specify how many rows they want to view, or the default will show the top 10 rows of the result set.\n",
    "\n",
    "4. **Exporting Data**:\n",
    "   A core feature of the project is the ability to export data into Excel and CSV formats. Users can choose whether to export the data:\n",
    "   - **To Excel**: Each query result is saved in a new sheet of an Excel workbook. The sheet names are automatically generated based on the current date and time, ensuring that no data is overwritten.\n",
    "   - **To CSV**: If CSV export is selected, the data is saved in a separate CSV file with a unique name based on the current timestamp. This allows for easy sharing and further analysis using standard spreadsheet software.\n",
    "\n",
    "### Libraries and Modules Used\n",
    "\n",
    "1. **Pandas**:\n",
    "   Pandas is a widely-used Python library for data manipulation and analysis. In this project, it is responsible for:\n",
    "   - Fetching and storing SQL query results in DataFrame format.\n",
    "   - Exporting data to Excel and CSV files.\n",
    "   \n",
    "2. **SQLAlchemy**:\n",
    "   SQLAlchemy is a popular SQL toolkit and Object Relational Mapper (ORM) that facilitates communication with SQL databases. It allows:\n",
    "   - Easy connection management with SQL Server.\n",
    "   - Safe and efficient execution of SQL queries.\n",
    "\n",
    "3. **Openpyxl**:\n",
    "   Openpyxl is a Python library used to read and write Excel files. It enables:\n",
    "   - Adding query results to new sheets within an existing Excel workbook.\n",
    "   \n",
    "4. **Pathlib**:\n",
    "   Pathlib is part of the Python standard library used for handling file and directory paths in an object-oriented way. It ensures:\n",
    "   - The proper creation of directories.\n",
    "   - Safe file path manipulation for exporting reports.\n",
    "   \n",
    "5. **Tabulate** (optional):\n",
    "   The Tabulate library is used to display DataFrame contents in a neatly formatted table within the console. This enhances readability and allows users to view data summaries directly.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Dynamic Data Export**: The ability to export SQL query results dynamically into either Excel or CSV formats, based on user preferences.\n",
    "- **Multi-Sheet Excel Reporting**: Each query is stored in a new sheet within the same Excel file, ensuring that no previous data is overwritten.\n",
    "- **Automated Filename Management**: Both Excel sheets and CSV files are given unique names using timestamps, allowing multiple reports to be saved without conflicts.\n",
    "- **Error Handling**: The project incorporates robust error handling mechanisms to ensure smooth operation, including database connection errors, file writing errors, and SQL execution issues.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This project offers a versatile and automated solution for generating database reports in structured formats. By leveraging popular Python libraries such as Pandas, SQLAlchemy, and Openpyxl, it simplifies the process of extracting, displaying, and exporting data from SQL Server databases. With the added ability to handle both Excel and CSV outputs, it provides a flexible tool for data analysis and reporting needs.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<section style=\"direction: rtl; text-align: justify; margin: 30px;\">\n",
    "\n",
    "### مقدمه پروژه\n",
    "\n",
    "این پروژه با هدف توسعه یک ابزار گزارش‌دهی خودکار طراحی شده است که دسترسی به داده‌های پایگاه داده SQL Server، اجرای کوئری‌های SQL و ذخیره داده‌های به‌دست‌آمده به گزارش‌های ساختاریافته را فراهم می‌کند. این ابزار به کاربران اجازه می‌دهد داده‌ها را استخراج کرده و در هر دو فرمت Excel و CSV ذخیره کنند، که انعطاف‌پذیری در مدیریت و ذخیره‌سازی داده‌ها را ارائه می‌دهد. این قابلیت به‌ویژه در محیط‌های مبتنی بر داده که گزارش‌دهی و مدیریت کارآمد داده‌ها اهمیت زیادی دارند، بسیار مفید است.\n",
    "\n",
    "### عملکرد کلی پروژه\n",
    "\n",
    "1. **اتصال به پایگاه داده**: \n",
    "   اولین گام در این فرایند، ایجاد یک اتصال به پایگاه داده SQL Server است. این کار با استفاده از کتابخانه `SQLAlchemy` انجام می‌شود که یک رابط قدرتمند برای تعامل با پایگاه‌های داده رابطه‌ای فراهم می‌کند. اتصال می‌تواند با یا بدون نام کاربری و رمز عبور انجام شود و این امکان را فراهم می‌آورد که در محیط‌های مختلف احراز هویت (SQL یا Windows) استفاده شود.\n",
    "\n",
    "2. **اجرای کوئری‌های SQL**:\n",
    "   پس از ایجاد اتصال، کاربران می‌توانند کوئری‌های SQL دلخواه خود را اجرا کرده و داده‌های مورد نیاز را از پایگاه داده بازیابی کنند. این کوئری‌ها می‌توانند شامل فیلتر، مرتب‌سازی یا تجمیع داده‌ها باشند. سپس ابزار داده‌ها را به یک DataFrame از کتابخانه Pandas منتقل می‌کند که امکان مدیریت و نمایش راحت‌تر نتایج را فراهم می‌کند.\n",
    "\n",
    "3. **نمایش داده‌ها**:\n",
    "   داده‌های بازیابی‌شده به‌صورت جدولی در کنسول نمایش داده می‌شوند. کاربران می‌توانند تعداد ردیف‌هایی که می‌خواهند مشاهده کنند را مشخص کنند، یا به‌طور پیش‌فرض ۱۰ ردیف اول نمایش داده می‌شود.\n",
    "\n",
    "4. **ذخیره داده‌ها**:\n",
    "   ویژگی اصلی این پروژه، توانایی ذخیره داده‌ها به فرمت‌های Excel و CSV است. کاربران می‌توانند انتخاب کنند که داده‌ها به‌صورت زیر ذخیره شوند:\n",
    "   - **در Excel**: هر نتیجه کوئری در یک شیت جدید از یک فایل Excel ذخیره می‌شود. نام شیت‌ها به‌صورت خودکار و بر اساس تاریخ و زمان فعلی ایجاد می‌شوند تا از بازنویسی داده‌ها جلوگیری شود.\n",
    "   - **در CSV**: اگر گزینه CSV انتخاب شود، داده‌ها در یک فایل CSV جداگانه با نام منحصربه‌فرد (بر اساس زمان فعلی) ذخیره می‌شوند که امکان به اشتراک‌گذاری و تحلیل بیشتر با نرم‌افزارهای استاندارد صفحه‌گسترده را فراهم می‌کند.\n",
    "\n",
    "### کتابخانه‌ها و ماژول‌های مورد استفاده\n",
    "\n",
    "1. **Pandas**:\n",
    "   Pandas یک کتابخانه بسیار پرکاربرد در پایتون برای تحلیل و مدیریت داده‌ها است. در این پروژه، مسئول:\n",
    "   - بارگذاری و ذخیره نتایج کوئری SQL در قالب DataFrame.\n",
    "   - ذخیره داده‌ها به فایل‌های Excel و CSV.\n",
    "   \n",
    "2. **SQLAlchemy**:\n",
    "   SQLAlchemy یک ابزار SQL و Mapper شیء رابطه‌ای (ORM) محبوب است که ارتباط با پایگاه‌های داده SQL را تسهیل می‌کند. این ابزار امکان:\n",
    "   - مدیریت آسان اتصال به SQL Server.\n",
    "   - اجرای ایمن و کارآمد کوئری‌های SQL را فراهم می‌کند.\n",
    "\n",
    "3. **Openpyxl**:\n",
    "   Openpyxl یک کتابخانه پایتون برای خواندن و نوشتن فایل‌های Excel است که در این پروژه برای:\n",
    "   - افزودن نتایج کوئری به شیت‌های جدید در یک فایل Excel موجود به کار می‌رود.\n",
    "   \n",
    "4. **Pathlib**:\n",
    "   Pathlib بخشی از کتابخانه استاندارد پایتون برای مدیریت مسیرهای فایل و دایرکتوری به شیوه‌ای شیءگرا است. این کتابخانه تضمین می‌کند که:\n",
    "   - دایرکتوری‌های مورد نیاز به‌درستی ایجاد شوند.\n",
    "   - مدیریت ایمن مسیرهای فایل برای ذخیره گزارش‌ها انجام شود.\n",
    "   \n",
    "5. **Tabulate** (اختیاری):\n",
    "   کتابخانه Tabulate برای نمایش محتوای DataFrame در قالب یک جدول مرتب‌شده در کنسول استفاده می‌شود. این کار خوانایی نتایج را بهبود می‌بخشد و به کاربران امکان می‌دهد خلاصه‌ای از داده‌ها را به‌راحتی مشاهده کنند.\n",
    "\n",
    "### ویژگی‌های کلیدی\n",
    "\n",
    "- **ذخیره سازی پویا**: امکان ذخیره سازی نتایج کوئری SQL به‌صورت پویا در فرمت‌های Excel یا CSV، بسته به نیاز کاربر.\n",
    "- **گزارش‌دهی چندشیتی در Excel**: هر کوئری در یک شیت جدید از یک فایل Excel ذخیره می‌شود و از بازنویسی داده‌ها جلوگیری می‌شود.\n",
    "- **مدیریت خودکار نام فایل‌ها**: شیت‌های Excel و فایل‌های CSV نام‌های منحصربه‌فردی بر اساس زمان فعلی دریافت می‌کنند که به کاربران اجازه می‌دهد چندین گزارش را بدون تداخل ذخیره کنند.\n",
    "- **مدیریت خطا**: پروژه شامل مکانیسم‌های مدیریت خطا برای تضمین عملکرد صحیح است که شامل مدیریت خطاهای اتصال به پایگاه داده، خطاهای نوشتن فایل و اجرای کوئری‌های SQL می‌باشد.\n",
    "\n",
    "### نتیجه‌گیری\n",
    "\n",
    "این پروژه یک راهکار همه‌کاره و خودکار برای تولید گزارش‌های پایگاه داده در قالب‌های ساختاریافته ارائه می‌دهد. با استفاده از کتابخانه‌های پرکاربردی مانند Pandas، SQLAlchemy و Openpyxl، این ابزار فرایند استخراج، نمایش و ذخیره‌سازی داده از پایگاه داده SQL Server را ساده می‌کند. با داشتن قابلیت ذخیره‌سازی خروجی به‌صورت Excel و CSV، این ابزار یک ابزار انعطاف‌پذیر برای نیازهای تحلیل و گزارش‌دهی داده‌ها فراهم می‌کند.\n",
    "\n",
    "</section>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calling the SQL Server Connection Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def create_connection(server, database, username=None, password=None):\n",
    "    \"\"\"\n",
    "    Create a connection to the SQL Server database using SQLAlchemy.\n",
    "    \n",
    "    Parameters:\n",
    "    - server: str, the name of the SQL Server\n",
    "    - database: str, the name of the database\n",
    "    - username: str, optional, SQL Server username (for SQL authentication)\n",
    "    - password: str, optional, SQL Server password (for SQL authentication)\n",
    "    \n",
    "    Returns:\n",
    "    - engine: sqlalchemy.engine.base.Engine, the SQLAlchemy engine object or None if the connection fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if username and password:\n",
    "            connection_string = f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "        else:\n",
    "            connection_string = f'mssql+pyodbc://{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "        \n",
    "        engine = create_engine(connection_string)\n",
    "        \n",
    "        # Test connection\n",
    "        with engine.connect() as conn:\n",
    "            logging.info(\"Connection successful!\")\n",
    "        \n",
    "        return engine\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        logging.error(f\"Connection failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### **Check if the database connection is successful**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 17:09:05,263 - INFO - Connection successful!\n",
      "2024-09-24 17:09:05,264 - INFO - Database connection established successfully.\n"
     ]
    }
   ],
   "source": [
    "def check_connection(engine):\n",
    "    if engine:\n",
    "        logging.info(\"Database connection established successfully.\")\n",
    "        return True\n",
    "    else:\n",
    "        logging.error(\"Failed to establish database connection.\")\n",
    "        return False\n",
    "\n",
    "# Call the create_connection function\n",
    "server = r'imsalione-pc\\imsalionedb'\n",
    "database = 'AdventureWorksLT2022'\n",
    "\n",
    "engine = create_connection(server, database)\n",
    "\n",
    "# Use the check_connection function to verify the connection\n",
    "if check_connection(engine):\n",
    "    # Proceed with database operations\n",
    "    pass\n",
    "else:\n",
    "    # Handle the failed connection\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### **Fetching and Displaying Data from SQL Server**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import exc\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the directory where you want to save the report files\n",
    "output_directory = Path(\"C:/Reports\")  # Adjust the path as needed\n",
    "output_directory.mkdir(parents=True, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "def fetch_and_display_data(engine, query, pnum=10, export_to_excel=False, export_to_csv=False):\n",
    "    \"\"\"\n",
    "    Fetch data from a SQL database and optionally export to Excel or CSV.\n",
    "    \n",
    "    Parameters:\n",
    "    - engine: SQLAlchemy engine object.\n",
    "    - query: SQL query string.\n",
    "    - pnum: int, number of rows to display (default is 10).\n",
    "    - export_to_excel: bool, whether to export data to an Excel file (default is False).\n",
    "    - export_to_csv: bool, whether to export data to a CSV file (default is False).\n",
    "    \"\"\"\n",
    "    \n",
    "    if engine:\n",
    "        try:\n",
    "            # Load data into a pandas DataFrame\n",
    "            df = pd.read_sql(query, engine)\n",
    "            \n",
    "            # Display the first pnum rows (or default 10 rows if pnum is not provided)\n",
    "            print(df.head(pnum).to_string(index=False, max_colwidth=25))\n",
    "\n",
    "            # Export to Excel if requested\n",
    "            if export_to_excel:\n",
    "                file_path = output_directory / \"report.xlsx\"\n",
    "                new_sheet_name = f\"Rep_{pd.Timestamp.now().strftime('%d%m%Y%H%M%S')}\"\n",
    "                \n",
    "                try:\n",
    "                    with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='new') as writer:\n",
    "                        df.to_excel(writer, sheet_name=new_sheet_name, index=False)\n",
    "                        print(f\"Data exported to {file_path} in sheet {new_sheet_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error writing to existing Excel file: {e}\")\n",
    "            \n",
    "            # Export to CSV if requested\n",
    "            if export_to_csv:\n",
    "                csv_file_path = output_directory / f\"report_{pd.Timestamp.now().strftime('%d%m%Y%H%M%S')}.csv\"\n",
    "                try:\n",
    "                    df.to_csv(csv_file_path, index=False)\n",
    "                    print(f\"Data exported to CSV at {csv_file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error writing to CSV file: {e}\")\n",
    "\n",
    "        except exc.SQLAlchemyError as db_error:\n",
    "            print(f\"Database error occurred: {db_error}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    else:\n",
    "        print(\"No database connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### **Executing SQL Query to Fetch and Display Table Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE_SCHEMA                TABLE_NAME\n",
      "         dbo                  ErrorLog\n",
      "         dbo              BuildVersion\n",
      "     SalesLT                   Address\n",
      "     SalesLT                  Customer\n",
      "     SalesLT           CustomerAddress\n",
      "     SalesLT                   Product\n",
      "     SalesLT           ProductCategory\n",
      "     SalesLT        ProductDescription\n",
      "     SalesLT              ProductModel\n",
      "     SalesLT ProductModelProductDes...\n",
      "     SalesLT          SalesOrderDetail\n",
      "     SalesLT          SalesOrderHeader\n",
      "     SalesLT    vProductAndDescription\n",
      "     SalesLT vProductModelCatalogDe...\n",
      "     SalesLT         vGetAllCategories\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT TABLE_SCHEMA, TABLE_NAME FROM INFORMATION_SCHEMA.TABLES\"\n",
    "fetch_and_display_data(engine, query, pnum=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AverageQTY\n",
      "          3\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT AVG(OrderQty) AS AverageQTY FROM SalesLT.SalesOrderDetail\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " OrderQty  ProductID  UnitPrice SalesClass\n",
      "        1        836     356.90    کم فروش\n",
      "        1        822     356.90    کم فروش\n",
      "        1        907      63.90    کم فروش\n",
      "        4        905     218.45     پرفروش\n",
      "        2        983     461.69    کم فروش\n",
      "        6        988     113.00     پرفروش\n",
      "        2        748     818.70    کم فروش\n",
      "        1        990     323.99    کم فروش\n",
      "        1        926     149.87    کم فروش\n",
      "        1        743     809.76    کم فروش\n",
      "        4        782    1376.99     پرفروش\n",
      "        2        918     158.43    کم فروش\n",
      "        4        780    1391.99     پرفروش\n",
      "        1        937      48.59    کم فروش\n",
      "        6        867      41.99     پرفروش\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT OrderQty, ProductID, UnitPrice, CASE\n",
    "WHEN OrderQty < 3 THEN N'کم فروش'\n",
    "WHEN OrderQty >= 3 THEN N'پرفروش'\n",
    "END AS SalesClass \n",
    "FROM SalesLT.SalesOrderDetail\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         COLUMN_NAME        DATA_TYPE\n",
      "ProductDescriptionID              int\n",
      "         Description         nvarchar\n",
      "             rowguid uniqueidentifier\n",
      "        ModifiedDate         datetime\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT COLUMN_NAME, DATA_TYPE\n",
    "FROM INFORMATION_SCHEMA.COLUMNS\n",
    "WHERE TABLE_NAME = 'ProductDescription';\n",
    "\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DateAverage  MaxYear  MinYear\n",
      "        2007     2008     2007\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT AVG(YEAR(ModifiedDate)) AS DateAverage,\n",
    "Max(YEAR(ModifiedDate)) AS MaxYear,\n",
    "Min(YEAR(ModifiedDate)) AS MinYear\n",
    "FROM SalesLT.ProductDescription\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ProductDescriptionID               Description                   rowguid            ModifiedDate\n",
      "                    3           Chromoly steel. 301EED3A-1A82-4855-99C... 2007-06-01 00:00:00.000\n",
      "                    4 Aluminum alloy cups; l... DFEBA528-DA11-4650-9D8... 2007-06-01 00:00:00.000\n",
      "                    5 Aluminum alloy cups an... F7178DA7-1A7E-4997-847... 2007-06-01 00:00:00.000\n",
      "                    8 Suitable for any type ... 8E6746E5-AD97-46E2-BD2... 2007-06-01 00:00:00.000\n",
      "                   64 This bike delivers a h... 7B1C4E90-85E2-4792-B47... 2007-06-01 00:00:00.000\n",
      "                   88 For true trail addicts... 4C1AD253-357E-4A98-B02... 2007-06-01 00:00:00.000\n",
      "                  128 Serious back-country r... 130709E6-8512-49B9-9F6... 2008-03-11 10:32:17.973\n",
      "                  168 Top-of-the-line compet... DB979DA6-4CC8-4171-9EC... 2007-06-01 00:00:00.000\n",
      "                  170 Suitable for any type ... EA772412-6369-4416-9CC... 2007-06-01 00:00:00.000\n",
      "                  209 Entry level adult bike... F5FF5FFD-CB7C-4AD6-BBC... 2007-06-01 00:00:00.000\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT * FROM SalesLT.ProductDescription\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SaleYEAR  YearCount\n",
      "        6        207\n",
      "        6        207\n",
      "        6        207\n",
      "        6        207\n",
      "        6        207\n",
      "        6        207\n",
      "        3        198\n",
      "        6        207\n",
      "        6        207\n",
      "        6        207\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT MONTH(ModifiedDate) AS SaleYEAR,\n",
    "DATEDIFF(MONTH, modifieddate, GETDATE())\n",
    "AS YearCount FROM SalesLT.ProductDescription\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database error occurred: (pyodbc.ProgrammingError) ('42S02', \"[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Invalid object name 'employee'. (208) (SQLExecDirectW)\")\n",
      "[SQL: SELECT fname, lname, hire_date , DATEDIFF(YEAR, hire_date, GETDATE())\n",
      "AS experience, \n",
      "CASE \n",
      "WHEN DATEDIFF(YEAR, hire_date, GETDATE()) > 30 THEN 'G1'\n",
      "WHEN DATEDIFF(YEAR, hire_date, GETDATE()) <= 30 THEN 'G2'\n",
      "END AS experienceClass\n",
      "FROM employee]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT fname, lname, hire_date , DATEDIFF(YEAR, hire_date, GETDATE())\n",
    "AS experience, \n",
    "CASE \n",
    "WHEN DATEDIFF(YEAR, hire_date, GETDATE()) > 30 THEN 'G1'\n",
    "WHEN DATEDIFF(YEAR, hire_date, GETDATE()) <= 30 THEN 'G2'\n",
    "END AS experienceClass\n",
    "FROM employee\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id stor_id  ord_num   ord_date  qty   payterms title_id\n",
      "  1    6380     6871 1994-09-14    5     Net 60   BU1032\n",
      " 15    7896   QQ2299 1993-10-28   15     Net 60   BU7832\n",
      " 17    7896     X999 1993-02-21   35 ON invoice   BU2075\n",
      " 19    8042 423LL930 1994-09-14   10 ON invoice   BU1032\n",
      " 20    8042     P723 1993-03-11   25     Net 30   BU1111\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT * FROM sales\n",
    "WHERE title_id like 'B%'\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title         type  NewPrice\n",
      "                  The Psychology of Computer Cooking UNDECIDED         0.00\n",
      "                                       Net Etiquette popular_comp      0.00\n",
      "                               The Gourmet Microwave mod_cook          2.99\n",
      "                     You Can Combat Computer Stress! business          2.99\n",
      "                                   Life Without Fear psychology        7.00\n",
      "                 Emotional Security: A New Algorithm psychology        7.99\n",
      "                                 Is Anger the Enemy? psychology       10.95\n",
      "           Fifty Years in Buckingham Palace Kitchens trad_cook        11.95\n",
      "Cooking with Computers: Surreptitious Balance Sheets business         11.95\n",
      "                                      Sushi, Anyone? trad_cook        14.99\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT title, type, isnull(price, 0)\n",
    "AS NewPrice\n",
    "FROM TITLES\n",
    "ORDER BY NewPrice\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          title\n",
      "                                       But Is It User Friendly?\n",
      "Computer Phobic AND Non-Phobic Individuals: Behavior Variations\n",
      "Onions, Leeks, and Garlic: Cooking Secrets of the Mediterranean\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT TOP 3 title FROM titles\n",
    "ORDER BY price DESC\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emp_id fname minit     lname  job_id  job_lvl pub_id  hire_date\n",
      "MGK44605M Matti     G Karttunen       6      220   0736 1994-05-01\n",
      "KJJ92907F Karla     J Jablonski       9      170   9999 1994-03-11\n",
      "PSP68661F Paula     S   Parente       8      125   1389 1994-01-19\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT TOP 3 * FROM employee\n",
    "ORDER BY hire_date DESC\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_id  price\n",
      "  1389  19.99\n",
      "  1389  11.95\n",
      "  1389  19.99\n",
      "  0877  19.99\n",
      "  1389  20.00\n",
      "  0736  10.95\n",
      "  0736   7.00\n",
      "  0736  19.99\n",
      "  0736   7.99\n",
      "  0877  11.95\n",
      "  0877  14.99\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT pub_id, price FROM titles \n",
    "WHERE price BETWEEN 7 AND 20\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_id                 pubdate\n",
      "  0877 2023-08-13 18:04:28.620\n",
      "  1389 1994-06-12 00:00:00.000\n",
      "  1389 2023-08-13 18:04:28.620\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"select pub_id, pubdate from titles\n",
    "where year(pubdate) > 1991\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SumPrice  AvgPrice  MaxPrice  MinPrice\n",
      "   236.26   14.7662     22.95      2.99\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT sum(price) as SumPrice,\n",
    "AVG(price) as AvgPrice,\n",
    "Max(price) as MaxPrice,\n",
    "Min(price) as MinPrice\n",
    "FROM titles\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NumberOfAuthors\n",
      "              23\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT COUNT(*) AS NumberOfAuthors FROM authors\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        type  AveragePrice\n",
      "business             13.73\n",
      "mod_cook             11.49\n",
      "popular_comp         21.48\n",
      "psychology           13.50\n",
      "trad_cook            15.96\n",
      "UNDECIDED              NaN\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT type, ROUND(AVG(price), 2) AS AveragePrice\n",
    "FROM titles\n",
    "GROUP BY type\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NumberOfHiredEmployee  YearOfHiring\n",
      "                     8          1990\n",
      "                     7          1991\n",
      "                     7          1992\n",
      "                     7          1993\n",
      "                     7          1989\n",
      "                     4          1988\n",
      "                     3          1994\n",
      "Data exported to C:\\Reports\\report.xlsx in sheet Rep_23092024152956\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"select count(*) as NumberOfHiredEmployee,\n",
    "year(hire_date) as YearOfHiring\n",
    "from employee\n",
    "group by year(hire_date)\n",
    "order by NumberOfHiredEmployee desc\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query, 10, export_to_excel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NumberOfHiredEmployee  YearOfHiring\n",
      "                     8          1990\n",
      "                     7          1991\n",
      "                     7          1992\n",
      "                     7          1993\n",
      "                     7          1989\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "select count(*) as NumberOfHiredEmployee,\n",
    "YEAR(hire_date) as YearOfHiring\n",
    "from employee\n",
    "group by YEAR(hire_date)\n",
    "having count(*) > 5\n",
    "order by NumberOfHiredEmployee desc\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CountOfPerson\n",
      "           847\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"select count(FirstName) as CountOfPerson \n",
    "from SalesLT.Customer\n",
    "\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
