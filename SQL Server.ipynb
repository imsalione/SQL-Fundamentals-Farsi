{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Server Connection Using SQLAlchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is designed to manage a SQL Server database using Python within a Jupyter Notebook environment. Here’s a comprehensive overview of what the project does:\n",
    "\n",
    "1. **Establishing a Database Connection**:\n",
    "   - The project begins by defining a function, `create_connection`, which establishes a connection to a SQL Server database using SQLAlchemy. This function takes parameters such as the server name, database name, and optionally, a username and password for SQL authentication. It constructs a connection string and attempts to connect to the database, returning an SQLAlchemy engine object if successful.\n",
    "\n",
    "2. **Fetching and Displaying Data**:\n",
    "   - Another function, `fetch_and_display_data`, is defined to execute SQL queries and fetch data from the connected database. This function uses the SQLAlchemy engine to run the provided SQL query and loads the results into a pandas DataFrame. The first 10 rows of the DataFrame are then displayed in a tabulated format using the `tabulate` library for better readability.\n",
    "\n",
    "3. **Executing SQL Queries**:\n",
    "   - The project includes examples of how to call these functions. For instance, it demonstrates how to connect to a specific SQL Server instance and database, and then how to fetch and display data from the `INFORMATION_SCHEMA.TABLES` and `sales` tables.\n",
    "\n",
    "4. **Error Handling**:\n",
    "   - Both functions include error handling to manage and report any issues that arise during the connection or data fetching processes. This ensures that users are informed of any problems and can take corrective actions.\n",
    "\n",
    "Overall, this project provides a practical approach to managing and interacting with a SQL Server database using Python. It leverages the power of pandas for data manipulation and SQLAlchemy for database connectivity, making it a robust solution for database management tasks within a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calling the SQL Server Connection Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def create_connection(server, database, username=None, password=None):\n",
    "    \"\"\"\n",
    "    Create a connection to the SQL Server database using SQLAlchemy.\n",
    "    \n",
    "    Parameters:\n",
    "    - server: str, the name of the SQL Server\n",
    "    - database: str, the name of the database\n",
    "    - username: str, optional, SQL Server username (for SQL authentication)\n",
    "    - password: str, optional, SQL Server password (for SQL authentication)\n",
    "    \n",
    "    Returns:\n",
    "    - engine: sqlalchemy.engine.base.Engine, the SQLAlchemy engine object or None if the connection fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if username and password:\n",
    "            connection_string = f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "        else:\n",
    "            connection_string = f'mssql+pyodbc://{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "        \n",
    "        engine = create_engine(connection_string)\n",
    "        \n",
    "        # Test connection\n",
    "        with engine.connect() as conn:\n",
    "            logging.info(\"Connection successful!\")\n",
    "        \n",
    "        return engine\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        logging.error(f\"Connection failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 00:21:54,997 - INFO - Connection successful!\n",
      "2024-09-22 00:21:54,999 - INFO - Database connection established successfully.\n"
     ]
    }
   ],
   "source": [
    "def check_connection(engine):\n",
    "    \"\"\"\n",
    "    Check if the database connection is successful.\n",
    "    \n",
    "    Parameters:\n",
    "    - engine: sqlalchemy.engine.base.Engine, the SQLAlchemy engine object\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if connection is successful, False otherwise\n",
    "    \"\"\"\n",
    "    if engine:\n",
    "        logging.info(\"Database connection established successfully.\")\n",
    "        return True\n",
    "    else:\n",
    "        logging.error(\"Failed to establish database connection.\")\n",
    "        return False\n",
    "\n",
    "# Call the create_connection function\n",
    "server = r'imsalione-pc\\imsalionedb'\n",
    "database = 'pubs'\n",
    "\n",
    "engine = create_connection(server, database)\n",
    "\n",
    "# Use the check_connection function to verify the connection\n",
    "if check_connection(engine):\n",
    "    # Proceed with database operations\n",
    "    pass\n",
    "else:\n",
    "    # Handle the failed connection\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fetching and Displaying Data from SQL Server**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import exc\n",
    "from pathlib import Path\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Define the directory where you want to save the Excel file\n",
    "output_directory = Path(\"C:/Reports\")  # Adjust the path as needed\n",
    "output_directory.mkdir(parents=True, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "def fetch_and_display_data(engine, query, pnum=10, export_to_excel=False):\n",
    "    \"\"\"\n",
    "    Fetch data from a SQL database and optionally export to Excel.\n",
    "    \n",
    "    Parameters:\n",
    "    - engine: SQLAlchemy engine object.\n",
    "    - query: SQL query string.\n",
    "    - pnum: int, number of rows to display (default is 10).\n",
    "    - export_to_excel: bool, whether to export data to an Excel file (default is False).\n",
    "    - excel_output_name: str, name of the Excel file to export (default is 'output.xlsx').\n",
    "    \"\"\"\n",
    "    \n",
    "    if engine:\n",
    "        try:\n",
    "            # Load data into a pandas DataFrame\n",
    "            df = pd.read_sql(query, engine)\n",
    "            \n",
    "            # Display the first pnum rows (or default 10 rows if pnum is not provided)\n",
    "            print(df.head(pnum).to_string(index=False))\n",
    "\n",
    "            # Export to Excel if requested\n",
    "            if export_to_excel:\n",
    "                # Combine directory path with file name\n",
    "                file_path = output_directory / \"output.xlsx\"\n",
    "\n",
    "                # Check if the Excel file already exists\n",
    "                if file_path.exists():\n",
    "                    try:\n",
    "                        # Append new sheet to the existing workbook\n",
    "                        with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='new') as writer:\n",
    "                            new_sheet_name = f\"Sheet_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "                            df.to_excel(writer, sheet_name=new_sheet_name, index=False)\n",
    "                            print(f\"Data exported to {file_path} in sheet {new_sheet_name}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error writing to existing Excel file: {e}\")\n",
    "                else:\n",
    "                    # Create a new Excel file and add the data to the first sheet\n",
    "                    df.to_excel(file_path, sheet_name='Sheet1', index=False)\n",
    "                    print(f\"Data exported to {file_path} in sheet 'Sheet1'\")\n",
    "\n",
    "        except exc.SQLAlchemyError as db_error:\n",
    "            print(f\"Database error occurred: {db_error}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    else:\n",
    "        print(\"No database connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing SQL Query to Fetch and Display Table Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE_CATALOG TABLE_SCHEMA  TABLE_NAME TABLE_TYPE\n",
      "         pubs          dbo sysdiagrams BASE TABLE\n",
      "         pubs          dbo     authors BASE TABLE\n",
      "         pubs          dbo  publishers BASE TABLE\n",
      "         pubs          dbo      titles BASE TABLE\n",
      "         pubs          dbo titleauthor BASE TABLE\n",
      "         pubs          dbo      stores BASE TABLE\n",
      "         pubs          dbo    roysched BASE TABLE\n",
      "         pubs          dbo   discounts BASE TABLE\n",
      "         pubs          dbo        jobs BASE TABLE\n",
      "         pubs          dbo    pub_info BASE TABLE\n",
      "Data exported to C:\\Reports\\output.xlsx in sheet 'Sheet1'\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM INFORMATION_SCHEMA.TABLES\"\n",
    "fetch_and_display_data(engine, query, pnum=10, export_to_excel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing SQL Query to Fetch and Display Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id stor_id  ord_num   ord_date  qty   payterms title_id\n",
      "  1    6380     6871 1994-09-14    5     Net 60   BU1032\n",
      "  2    6380     722a 1994-09-13    3     Net 60   PS2091\n",
      "  3    7066    A2976 1993-05-24   50     Net 30   PC8888\n",
      "  4    7066 QA7442.3 1994-09-13   75 ON invoice   PS2091\n",
      "  5    7067    D4482 1994-09-14   10     Net 60   PS2091\n",
      "  6    7067    P2121 1992-06-15   40     Net 30   TC3218\n",
      "  7    7067    P2121 1992-06-15   20     Net 30   TC4203\n",
      "  8    7067    P2121 1992-06-15   20     Net 30   TC7777\n",
      "  9    7131  N914008 1994-09-14   20     Net 30   PS2091\n",
      " 10    7131  N914014 1994-09-14   25     Net 30   MC3021\n",
      " 11    7131   P3087a 1993-05-29   20     Net 60   PS1372\n",
      " 12    7131   P3087a 1993-05-29   25     Net 60   PS2106\n",
      " 13    7131   P3087a 1993-05-29   15     Net 60   PS3333\n",
      " 14    7131   P3087a 1993-05-29   25     Net 60   PS7777\n",
      " 15    7896   QQ2299 1993-10-28   15     Net 60   BU7832\n",
      " 16    7896    TQ456 1993-12-12   10     Net 60   MC2222\n",
      " 17    7896     X999 1993-02-21   35 ON invoice   BU2075\n",
      " 18    8042 423LL922 1994-09-14   15 ON invoice   MC3021\n",
      " 19    8042 423LL930 1994-09-14   10 ON invoice   BU1032\n",
      " 20    8042     P723 1993-03-11   25     Net 30   BU1111\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM sales\"\n",
    "fetch_and_display_data(engine, query, 20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id stor_id  ord_num   ord_date  qty   payterms title_id SalesClass\n",
      "  1    6380     6871 1994-09-14    5     Net 60   BU1032    کم فروش\n",
      "  2    6380     722a 1994-09-13    3     Net 60   PS2091    کم فروش\n",
      "  3    7066    A2976 1993-05-24   50     Net 30   PC8888     پرفروش\n",
      "  4    7066 QA7442.3 1994-09-13   75 ON invoice   PS2091     پرفروش\n",
      "  5    7067    D4482 1994-09-14   10     Net 60   PS2091    کم فروش\n",
      "  6    7067    P2121 1992-06-15   40     Net 30   TC3218     پرفروش\n",
      "  7    7067    P2121 1992-06-15   20     Net 30   TC4203    کم فروش\n",
      "  8    7067    P2121 1992-06-15   20     Net 30   TC7777    کم فروش\n",
      "  9    7131  N914008 1994-09-14   20     Net 30   PS2091    کم فروش\n",
      " 10    7131  N914014 1994-09-14   25     Net 30   MC3021    کم فروش\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT *, CASE\n",
    "WHEN qty < 30 THEN N'کم فروش'\n",
    "WHEN qty >= 30 THEN N'پرفروش'\n",
    "END AS SalesClass \n",
    "FROM sales\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query, 10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emp_id     fname minit     lname  job_id  job_lvl pub_id  hire_date  experience\n",
      "PMA42628M     Paolo     M   Accorti      13       35   0877 1992-08-27          32\n",
      "PSA89086M     Pedro     S    Afonso      14       89   1389 1990-12-24          34\n",
      "VPA30890F  Victoria     P  Ashworth       6      140   0877 1990-09-13          34\n",
      "H-B39728F     Helen         Bennett      12       35   0877 1989-09-21          35\n",
      "L-B31947F    Lesley           Brown       7      120   0877 1991-02-13          33\n",
      "F-C16315M Francisco           Chang       4      227   9952 1990-11-03          34\n",
      "PTC11962M    Philip     T    Cramer       2      215   9952 1989-11-11          35\n",
      "A-C71970F      Aria            Cruz      10       87   1389 1991-10-26          33\n",
      "AMD15433F       Ann     M     Devon       3      200   9952 1991-07-16          33\n",
      "ARD36773F   Anabela     R Domingues       8      100   0877 1993-01-27          31\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT * , DATEDIFF(YEAR, hire_date, GETDATE())\n",
    "                       AS experience \n",
    "                       FROM employee\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query , 10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fname     lname  hire_date  experience experienceClass\n",
      "    Paolo   Accorti 1992-08-27          32              G1\n",
      "    Pedro    Afonso 1990-12-24          34              G1\n",
      " Victoria  Ashworth 1990-09-13          34              G1\n",
      "    Helen   Bennett 1989-09-21          35              G1\n",
      "   Lesley     Brown 1991-02-13          33              G1\n",
      "Francisco     Chang 1990-11-03          34              G1\n",
      "   Philip    Cramer 1989-11-11          35              G1\n",
      "     Aria      Cruz 1991-10-26          33              G1\n",
      "      Ann     Devon 1991-07-16          33              G1\n",
      "  Anabela Domingues 1993-01-27          31              G1\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT fname, lname, hire_date , DATEDIFF(YEAR, hire_date, GETDATE())\n",
    "                       AS experience, \n",
    "                       CASE \n",
    "                       WHEN DATEDIFF(YEAR, hire_date, GETDATE()) > 30 THEN 'G1'\n",
    "                       WHEN DATEDIFF(YEAR, hire_date, GETDATE()) <= 30 THEN 'G2'\n",
    "                       END AS experienceClass\n",
    "                       FROM employee\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query , 10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id stor_id  ord_num   ord_date  qty   payterms title_id\n",
      "  1    6380     6871 1994-09-14    5     Net 60   BU1032\n",
      " 15    7896   QQ2299 1993-10-28   15     Net 60   BU7832\n",
      " 17    7896     X999 1993-02-21   35 ON invoice   BU2075\n",
      " 19    8042 423LL930 1994-09-14   10 ON invoice   BU1032\n",
      " 20    8042     P723 1993-03-11   25     Net 30   BU1111\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT * FROM sales\n",
    "WHERE title_id like 'B%'\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query , 20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title         type  NewPrice\n",
      "                  The Psychology of Computer Cooking UNDECIDED         0.00\n",
      "                                       Net Etiquette popular_comp      0.00\n",
      "                               The Gourmet Microwave mod_cook          2.99\n",
      "                     You Can Combat Computer Stress! business          2.99\n",
      "                                   Life Without Fear psychology        7.00\n",
      "                 Emotional Security: A New Algorithm psychology        7.99\n",
      "                                 Is Anger the Enemy? psychology       10.95\n",
      "           Fifty Years in Buckingham Palace Kitchens trad_cook        11.95\n",
      "Cooking with Computers: Surreptitious Balance Sheets business         11.95\n",
      "                                      Sushi, Anyone? trad_cook        14.99\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT title, type, isnull(price, 0)\n",
    "AS NewPrice\n",
    "FROM TITLES\n",
    "ORDER BY NewPrice\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query , 10, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
