{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SQL-Fundamentals-Farsi**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<section style=\"direction: ltr; text-align: justify; margin: 30px;\">\n",
    "\n",
    "### Project Introduction\n",
    "\n",
    "This project is aimed at developing an automated reporting tool that facilitates accessing data from SQL Server databases, executing SQL queries, and exporting the resulting data into structured reports. The tool allows users to extract data and save it in both Excel and CSV formats, providing flexibility in data handling and storage. This functionality is particularly beneficial in data-driven environments where efficient reporting and data management are critical.\n",
    "\n",
    "### General Workflow of the Project\n",
    "\n",
    "1. **Database Connection**: \n",
    "   The first step in the process involves establishing a connection to the SQL Server database. This is done using the `SQLAlchemy` library, which provides a robust interface for interacting with relational databases. The connection can be made with or without login credentials, allowing flexibility in different authentication environments (SQL or Windows authentication).\n",
    "\n",
    "2. **Executing SQL Queries**:\n",
    "   After establishing a connection, users can execute their desired SQL queries to retrieve data from the database. These queries can include filtering, sorting, or aggregating data as per business needs. The tool then fetches the data into a Pandas DataFrame, which makes it easier to manipulate and display the results.\n",
    "\n",
    "3. **Data Display**:\n",
    "   The retrieved data is displayed in the console in a tabular format. Users can specify how many rows they want to view, or the default will show the top 10 rows of the result set.\n",
    "\n",
    "4. **Exporting Data**:\n",
    "   A core feature of the project is the ability to export data into Excel and CSV formats. Users can choose whether to export the data:\n",
    "   - **To Excel**: Each query result is saved in a new sheet of an Excel workbook. The sheet names are automatically generated based on the current date and time, ensuring that no data is overwritten.\n",
    "   - **To CSV**: If CSV export is selected, the data is saved in a separate CSV file with a unique name based on the current timestamp. This allows for easy sharing and further analysis using standard spreadsheet software.\n",
    "\n",
    "### Libraries and Modules Used\n",
    "\n",
    "1. **Pandas**:\n",
    "   Pandas is a widely-used Python library for data manipulation and analysis. In this project, it is responsible for:\n",
    "   - Fetching and storing SQL query results in DataFrame format.\n",
    "   - Exporting data to Excel and CSV files.\n",
    "   \n",
    "2. **SQLAlchemy**:\n",
    "   SQLAlchemy is a popular SQL toolkit and Object Relational Mapper (ORM) that facilitates communication with SQL databases. It allows:\n",
    "   - Easy connection management with SQL Server.\n",
    "   - Safe and efficient execution of SQL queries.\n",
    "\n",
    "3. **Openpyxl**:\n",
    "   Openpyxl is a Python library used to read and write Excel files. It enables:\n",
    "   - Adding query results to new sheets within an existing Excel workbook.\n",
    "   \n",
    "4. **Pathlib**:\n",
    "   Pathlib is part of the Python standard library used for handling file and directory paths in an object-oriented way. It ensures:\n",
    "   - The proper creation of directories.\n",
    "   - Safe file path manipulation for exporting reports.\n",
    "   \n",
    "5. **Tabulate** (optional):\n",
    "   The Tabulate library is used to display DataFrame contents in a neatly formatted table within the console. This enhances readability and allows users to view data summaries directly.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Dynamic Data Export**: The ability to export SQL query results dynamically into either Excel or CSV formats, based on user preferences.\n",
    "- **Multi-Sheet Excel Reporting**: Each query is stored in a new sheet within the same Excel file, ensuring that no previous data is overwritten.\n",
    "- **Automated Filename Management**: Both Excel sheets and CSV files are given unique names using timestamps, allowing multiple reports to be saved without conflicts.\n",
    "- **Error Handling**: The project incorporates robust error handling mechanisms to ensure smooth operation, including database connection errors, file writing errors, and SQL execution issues.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This project offers a versatile and automated solution for generating database reports in structured formats. By leveraging popular Python libraries such as Pandas, SQLAlchemy, and Openpyxl, it simplifies the process of extracting, displaying, and exporting data from SQL Server databases. With the added ability to handle both Excel and CSV outputs, it provides a flexible tool for data analysis and reporting needs.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<section style=\"direction: rtl; text-align: justify; margin: 30px;\">\n",
    "\n",
    "### مقدمه پروژه\n",
    "\n",
    "این پروژه با هدف توسعه یک ابزار گزارش‌دهی خودکار طراحی شده است که دسترسی به داده‌های پایگاه داده SQL Server، اجرای کوئری‌های SQL و صادرات داده‌های به‌دست‌آمده به گزارش‌های ساختاریافته را فراهم می‌کند. این ابزار به کاربران اجازه می‌دهد داده‌ها را استخراج کرده و در هر دو فرمت Excel و CSV ذخیره کنند، که انعطاف‌پذیری در مدیریت و ذخیره‌سازی داده‌ها را ارائه می‌دهد. این قابلیت به‌ویژه در محیط‌های مبتنی بر داده که گزارش‌دهی و مدیریت کارآمد داده‌ها اهمیت زیادی دارند، بسیار مفید است.\n",
    "\n",
    "### عملکرد کلی پروژه\n",
    "\n",
    "1. **اتصال به پایگاه داده**: \n",
    "   اولین گام در این فرایند، ایجاد یک اتصال به پایگاه داده SQL Server است. این کار با استفاده از کتابخانه `SQLAlchemy` انجام می‌شود که یک رابط قدرتمند برای تعامل با پایگاه‌های داده رابطه‌ای فراهم می‌کند. اتصال می‌تواند با یا بدون نام کاربری و رمز عبور انجام شود و این امکان را فراهم می‌آورد که در محیط‌های مختلف احراز هویت (SQL یا Windows) استفاده شود.\n",
    "\n",
    "2. **اجرای کوئری‌های SQL**:\n",
    "   پس از ایجاد اتصال، کاربران می‌توانند کوئری‌های SQL دلخواه خود را اجرا کرده و داده‌های مورد نیاز را از پایگاه داده بازیابی کنند. این کوئری‌ها می‌توانند شامل فیلتر، مرتب‌سازی یا تجمیع داده‌ها باشند. سپس ابزار داده‌ها را به یک DataFrame از کتابخانه Pandas منتقل می‌کند که امکان مدیریت و نمایش راحت‌تر نتایج را فراهم می‌کند.\n",
    "\n",
    "3. **نمایش داده‌ها**:\n",
    "   داده‌های بازیابی‌شده به‌صورت جدولی در کنسول نمایش داده می‌شوند. کاربران می‌توانند تعداد ردیف‌هایی که می‌خواهند مشاهده کنند را مشخص کنند، یا به‌طور پیش‌فرض ۱۰ ردیف اول نمایش داده می‌شود.\n",
    "\n",
    "4. **صادرات داده‌ها**:\n",
    "   ویژگی اصلی این پروژه، توانایی صادرات داده‌ها به فرمت‌های Excel و CSV است. کاربران می‌توانند انتخاب کنند که داده‌ها به‌صورت زیر ذخیره شوند:\n",
    "   - **در Excel**: هر نتیجه کوئری در یک شیت جدید از یک فایل Excel ذخیره می‌شود. نام شیت‌ها به‌صورت خودکار و بر اساس تاریخ و زمان فعلی ایجاد می‌شوند تا از بازنویسی داده‌ها جلوگیری شود.\n",
    "   - **در CSV**: اگر گزینه CSV انتخاب شود، داده‌ها در یک فایل CSV جداگانه با نام منحصربه‌فرد (بر اساس زمان فعلی) ذخیره می‌شوند که امکان به اشتراک‌گذاری و تحلیل بیشتر با نرم‌افزارهای استاندارد صفحه‌گسترده را فراهم می‌کند.\n",
    "\n",
    "### کتابخانه‌ها و ماژول‌های مورد استفاده\n",
    "\n",
    "1. **Pandas**:\n",
    "   Pandas یک کتابخانه بسیار پرکاربرد در پایتون برای تحلیل و مدیریت داده‌ها است. در این پروژه، مسئول:\n",
    "   - بارگذاری و ذخیره نتایج کوئری SQL در قالب DataFrame.\n",
    "   - صادرات داده‌ها به فایل‌های Excel و CSV.\n",
    "   \n",
    "2. **SQLAlchemy**:\n",
    "   SQLAlchemy یک ابزار SQL و Mapper شیء رابطه‌ای (ORM) محبوب است که ارتباط با پایگاه‌های داده SQL را تسهیل می‌کند. این ابزار امکان:\n",
    "   - مدیریت آسان اتصال به SQL Server.\n",
    "   - اجرای ایمن و کارآمد کوئری‌های SQL را فراهم می‌کند.\n",
    "\n",
    "3. **Openpyxl**:\n",
    "   Openpyxl یک کتابخانه پایتون برای خواندن و نوشتن فایل‌های Excel است که در این پروژه برای:\n",
    "   - افزودن نتایج کوئری به شیت‌های جدید در یک فایل Excel موجود به کار می‌رود.\n",
    "   \n",
    "4. **Pathlib**:\n",
    "   Pathlib بخشی از کتابخانه استاندارد پایتون برای مدیریت مسیرهای فایل و دایرکتوری به شیوه‌ای شیءگرا است. این کتابخانه تضمین می‌کند که:\n",
    "   - دایرکتوری‌های مورد نیاز به‌درستی ایجاد شوند.\n",
    "   - مدیریت ایمن مسیرهای فایل برای صادرات گزارش‌ها انجام شود.\n",
    "   \n",
    "5. **Tabulate** (اختیاری):\n",
    "   کتابخانه Tabulate برای نمایش محتوای DataFrame در قالب یک جدول مرتب‌شده در کنسول استفاده می‌شود. این کار خوانایی نتایج را بهبود می‌بخشد و به کاربران امکان می‌دهد خلاصه‌ای از داده‌ها را به‌راحتی مشاهده کنند.\n",
    "\n",
    "### ویژگی‌های کلیدی\n",
    "\n",
    "- **صادرات پویا**: امکان صادرات نتایج کوئری SQL به‌صورت پویا در فرمت‌های Excel یا CSV، بسته به نیاز کاربر.\n",
    "- **گزارش‌دهی چندشیتی در Excel**: هر کوئری در یک شیت جدید از یک فایل Excel ذخیره می‌شود و از بازنویسی داده‌ها جلوگیری می‌شود.\n",
    "- **مدیریت خودکار نام فایل‌ها**: شیت‌های Excel و فایل‌های CSV نام‌های منحصربه‌فردی بر اساس زمان فعلی دریافت می‌کنند که به کاربران اجازه می‌دهد چندین گزارش را بدون تداخل ذخیره کنند.\n",
    "- **مدیریت خطا**: پروژه شامل مکانیسم‌های مدیریت خطا برای تضمین عملکرد صحیح است که شامل مدیریت خطاهای اتصال به پایگاه داده، خطاهای نوشتن فایل و اجرای کوئری‌های SQL می‌باشد.\n",
    "\n",
    "### نتیجه‌گیری\n",
    "\n",
    "این پروژه یک راهکار همه‌کاره و خودکار برای تولید گزارش‌های پایگاه داده در قالب‌های ساختاریافته ارائه می‌دهد. با استفاده از کتابخانه‌های پرکاربردی مانند Pandas، SQLAlchemy و Openpyxl، این ابزار فرایند استخراج، نمایش و صادرات داده از پایگاه داده SQL Server را ساده می‌کند. با داشتن قابلیت ذخیره‌سازی خروجی به‌صورت Excel و CSV، این ابزار یک ابزار انعطاف‌پذیر برای نیازهای تحلیل و گزارش‌دهی داده‌ها فراهم می‌کند.\n",
    "\n",
    "</section>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calling the SQL Server Connection Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def create_connection(server, database, username=None, password=None):\n",
    "    \"\"\"\n",
    "    Create a connection to the SQL Server database using SQLAlchemy.\n",
    "    \n",
    "    Parameters:\n",
    "    - server: str, the name of the SQL Server\n",
    "    - database: str, the name of the database\n",
    "    - username: str, optional, SQL Server username (for SQL authentication)\n",
    "    - password: str, optional, SQL Server password (for SQL authentication)\n",
    "    \n",
    "    Returns:\n",
    "    - engine: sqlalchemy.engine.base.Engine, the SQLAlchemy engine object or None if the connection fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if username and password:\n",
    "            connection_string = f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "        else:\n",
    "            connection_string = f'mssql+pyodbc://{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "        \n",
    "        engine = create_engine(connection_string)\n",
    "        \n",
    "        # Test connection\n",
    "        with engine.connect() as conn:\n",
    "            logging.info(\"Connection successful!\")\n",
    "        \n",
    "        return engine\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        logging.error(f\"Connection failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### **Check if the database connection is successful**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 18:19:34,967 - INFO - Connection successful!\n",
      "2024-09-22 18:19:34,969 - INFO - Database connection established successfully.\n"
     ]
    }
   ],
   "source": [
    "def check_connection(engine):\n",
    "    if engine:\n",
    "        logging.info(\"Database connection established successfully.\")\n",
    "        return True\n",
    "    else:\n",
    "        logging.error(\"Failed to establish database connection.\")\n",
    "        return False\n",
    "\n",
    "# Call the create_connection function\n",
    "server = r'imsalione-pc\\imsalionedb'\n",
    "database = 'pubs'\n",
    "\n",
    "engine = create_connection(server, database)\n",
    "\n",
    "# Use the check_connection function to verify the connection\n",
    "if check_connection(engine):\n",
    "    # Proceed with database operations\n",
    "    pass\n",
    "else:\n",
    "    # Handle the failed connection\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### **Fetching and Displaying Data from SQL Server**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import exc\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the directory where you want to save the report files\n",
    "output_directory = Path(\"C:/Reports\")  # Adjust the path as needed\n",
    "output_directory.mkdir(parents=True, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "def fetch_and_display_data(engine, query, pnum=10, export_to_excel=False, export_to_csv=False):\n",
    "    \"\"\"\n",
    "    Fetch data from a SQL database and optionally export to Excel or CSV.\n",
    "    \n",
    "    Parameters:\n",
    "    - engine: SQLAlchemy engine object.\n",
    "    - query: SQL query string.\n",
    "    - pnum: int, number of rows to display (default is 10).\n",
    "    - export_to_excel: bool, whether to export data to an Excel file (default is False).\n",
    "    - export_to_csv: bool, whether to export data to a CSV file (default is False).\n",
    "    \"\"\"\n",
    "    \n",
    "    if engine:\n",
    "        try:\n",
    "            # Load data into a pandas DataFrame\n",
    "            df = pd.read_sql(query, engine)\n",
    "            \n",
    "            # Display the first pnum rows (or default 10 rows if pnum is not provided)\n",
    "            print(df.head(pnum).to_string(index=False))\n",
    "\n",
    "            # Export to Excel if requested\n",
    "            if export_to_excel:\n",
    "                file_path = output_directory / \"report.xlsx\"\n",
    "                new_sheet_name = f\"Rep_{pd.Timestamp.now().strftime('%d%m%Y%H%M%S')}\"\n",
    "                \n",
    "                try:\n",
    "                    with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='new') as writer:\n",
    "                        df.to_excel(writer, sheet_name=new_sheet_name, index=False)\n",
    "                        print(f\"Data exported to {file_path} in sheet {new_sheet_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error writing to existing Excel file: {e}\")\n",
    "            \n",
    "            # Export to CSV if requested\n",
    "            if export_to_csv:\n",
    "                csv_file_path = output_directory / f\"report_{pd.Timestamp.now().strftime('%d%m%Y%H%M%S')}.csv\"\n",
    "                try:\n",
    "                    df.to_csv(csv_file_path, index=False)\n",
    "                    print(f\"Data exported to CSV at {csv_file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error writing to CSV file: {e}\")\n",
    "\n",
    "        except exc.SQLAlchemyError as db_error:\n",
    "            print(f\"Database error occurred: {db_error}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    else:\n",
    "        print(\"No database connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### **Executing SQL Query to Fetch and Display Table Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE_CATALOG TABLE_SCHEMA  TABLE_NAME TABLE_TYPE\n",
      "         pubs          dbo sysdiagrams BASE TABLE\n",
      "         pubs          dbo     authors BASE TABLE\n",
      "         pubs          dbo  publishers BASE TABLE\n",
      "         pubs          dbo      titles BASE TABLE\n",
      "         pubs          dbo titleauthor BASE TABLE\n",
      "         pubs          dbo      stores BASE TABLE\n",
      "         pubs          dbo    roysched BASE TABLE\n",
      "         pubs          dbo   discounts BASE TABLE\n",
      "         pubs          dbo        jobs BASE TABLE\n",
      "         pubs          dbo    pub_info BASE TABLE\n",
      "Data exported to CSV at C:\\Reports\\report_22092024155643.csv\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM INFORMATION_SCHEMA.TABLES\"\n",
    "fetch_and_display_data(engine, query, pnum=10, export_to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id stor_id  ord_num   ord_date  qty   payterms title_id\n",
      "  1    6380     6871 1994-09-14    5     Net 60   BU1032\n",
      "  2    6380     722a 1994-09-13    3     Net 60   PS2091\n",
      "  3    7066    A2976 1993-05-24   50     Net 30   PC8888\n",
      "  4    7066 QA7442.3 1994-09-13   75 ON invoice   PS2091\n",
      "  5    7067    D4482 1994-09-14   10     Net 60   PS2091\n",
      "  6    7067    P2121 1992-06-15   40     Net 30   TC3218\n",
      "  7    7067    P2121 1992-06-15   20     Net 30   TC4203\n",
      "  8    7067    P2121 1992-06-15   20     Net 30   TC7777\n",
      "  9    7131  N914008 1994-09-14   20     Net 30   PS2091\n",
      " 10    7131  N914014 1994-09-14   25     Net 30   MC3021\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM sales\"\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id stor_id  ord_num   ord_date  qty   payterms title_id SalesClass\n",
      "  1    6380     6871 1994-09-14    5     Net 60   BU1032    کم فروش\n",
      "  2    6380     722a 1994-09-13    3     Net 60   PS2091    کم فروش\n",
      "  3    7066    A2976 1993-05-24   50     Net 30   PC8888     پرفروش\n",
      "  4    7066 QA7442.3 1994-09-13   75 ON invoice   PS2091     پرفروش\n",
      "  5    7067    D4482 1994-09-14   10     Net 60   PS2091    کم فروش\n",
      "  6    7067    P2121 1992-06-15   40     Net 30   TC3218     پرفروش\n",
      "  7    7067    P2121 1992-06-15   20     Net 30   TC4203    کم فروش\n",
      "  8    7067    P2121 1992-06-15   20     Net 30   TC7777    کم فروش\n",
      "  9    7131  N914008 1994-09-14   20     Net 30   PS2091    کم فروش\n",
      " 10    7131  N914014 1994-09-14   25     Net 30   MC3021    کم فروش\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT *, CASE\n",
    "WHEN qty < 30 THEN N'کم فروش'\n",
    "WHEN qty >= 30 THEN N'پرفروش'\n",
    "END AS SalesClass \n",
    "FROM sales\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emp_id     fname minit     lname  job_id  job_lvl pub_id  hire_date  experience\n",
      "PMA42628M     Paolo     M   Accorti      13       35   0877 1992-08-27          32\n",
      "PSA89086M     Pedro     S    Afonso      14       89   1389 1990-12-24          34\n",
      "VPA30890F  Victoria     P  Ashworth       6      140   0877 1990-09-13          34\n",
      "H-B39728F     Helen         Bennett      12       35   0877 1989-09-21          35\n",
      "L-B31947F    Lesley           Brown       7      120   0877 1991-02-13          33\n",
      "F-C16315M Francisco           Chang       4      227   9952 1990-11-03          34\n",
      "PTC11962M    Philip     T    Cramer       2      215   9952 1989-11-11          35\n",
      "A-C71970F      Aria            Cruz      10       87   1389 1991-10-26          33\n",
      "AMD15433F       Ann     M     Devon       3      200   9952 1991-07-16          33\n",
      "ARD36773F   Anabela     R Domingues       8      100   0877 1993-01-27          31\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT * , DATEDIFF(YEAR, hire_date, GETDATE())\n",
    "                       AS experience \n",
    "                       FROM employee\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fname     lname  hire_date  experience experienceClass\n",
      "    Paolo   Accorti 1992-08-27          32              G1\n",
      "    Pedro    Afonso 1990-12-24          34              G1\n",
      " Victoria  Ashworth 1990-09-13          34              G1\n",
      "    Helen   Bennett 1989-09-21          35              G1\n",
      "   Lesley     Brown 1991-02-13          33              G1\n",
      "Francisco     Chang 1990-11-03          34              G1\n",
      "   Philip    Cramer 1989-11-11          35              G1\n",
      "     Aria      Cruz 1991-10-26          33              G1\n",
      "      Ann     Devon 1991-07-16          33              G1\n",
      "  Anabela Domingues 1993-01-27          31              G1\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT fname, lname, hire_date , DATEDIFF(YEAR, hire_date, GETDATE())\n",
    "                       AS experience, \n",
    "                       CASE \n",
    "                       WHEN DATEDIFF(YEAR, hire_date, GETDATE()) > 30 THEN 'G1'\n",
    "                       WHEN DATEDIFF(YEAR, hire_date, GETDATE()) <= 30 THEN 'G2'\n",
    "                       END AS experienceClass\n",
    "                       FROM employee\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id stor_id  ord_num   ord_date  qty   payterms title_id\n",
      "  1    6380     6871 1994-09-14    5     Net 60   BU1032\n",
      " 15    7896   QQ2299 1993-10-28   15     Net 60   BU7832\n",
      " 17    7896     X999 1993-02-21   35 ON invoice   BU2075\n",
      " 19    8042 423LL930 1994-09-14   10 ON invoice   BU1032\n",
      " 20    8042     P723 1993-03-11   25     Net 30   BU1111\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT * FROM sales\n",
    "WHERE title_id like 'B%'\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title         type  NewPrice\n",
      "                  The Psychology of Computer Cooking UNDECIDED         0.00\n",
      "                                       Net Etiquette popular_comp      0.00\n",
      "                               The Gourmet Microwave mod_cook          2.99\n",
      "                     You Can Combat Computer Stress! business          2.99\n",
      "                                   Life Without Fear psychology        7.00\n",
      "                 Emotional Security: A New Algorithm psychology        7.99\n",
      "                                 Is Anger the Enemy? psychology       10.95\n",
      "           Fifty Years in Buckingham Palace Kitchens trad_cook        11.95\n",
      "Cooking with Computers: Surreptitious Balance Sheets business         11.95\n",
      "                                      Sushi, Anyone? trad_cook        14.99\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT title, type, isnull(price, 0)\n",
    "AS NewPrice\n",
    "FROM TITLES\n",
    "ORDER BY NewPrice\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          title\n",
      "                                       But Is It User Friendly?\n",
      "Computer Phobic AND Non-Phobic Individuals: Behavior Variations\n",
      "Onions, Leeks, and Garlic: Cooking Secrets of the Mediterranean\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT TOP 3 title FROM titles\n",
    "ORDER BY price DESC\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emp_id fname minit     lname  job_id  job_lvl pub_id  hire_date\n",
      "MGK44605M Matti     G Karttunen       6      220   0736 1994-05-01\n",
      "KJJ92907F Karla     J Jablonski       9      170   9999 1994-03-11\n",
      "PSP68661F Paula     S   Parente       8      125   1389 1994-01-19\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT TOP 3 * FROM employee\n",
    "ORDER BY hire_date DESC\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_id  price\n",
      "  1389  19.99\n",
      "  1389  11.95\n",
      "  1389  19.99\n",
      "  0877  19.99\n",
      "  1389  20.00\n",
      "  0736  10.95\n",
      "  0736   7.00\n",
      "  0736  19.99\n",
      "  0736   7.99\n",
      "  0877  11.95\n",
      "  0877  14.99\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT pub_id, price FROM titles \n",
    "WHERE price BETWEEN 7 AND 20\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_id                 pubdate\n",
      "  0877 2023-08-13 18:04:28.620\n",
      "  1389 1994-06-12 00:00:00.000\n",
      "  1389 2023-08-13 18:04:28.620\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"select pub_id, pubdate from titles\n",
    "where year(pubdate) > 1991\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SumPrice  AvgPrice  MaxPrice  MinPrice\n",
      "   236.26   14.7662     22.95      2.99\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT sum(price) as SumPrice,\n",
    "AVG(price) as AvgPrice,\n",
    "Max(price) as MaxPrice,\n",
    "Min(price) as MinPrice\n",
    "FROM titles\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
