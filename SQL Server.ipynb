{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SQL-Fundamentals-Farsi**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<section style=\"direction: ltr; text-align: justify; margin: 30px;\">\n",
    "\n",
    "### Project Introduction\n",
    "\n",
    "This project is designed to create a tool for accessing SQL Server databases, executing various queries, and extracting data. The main objective is to automate the generation of comprehensive reports from database data and save them in Excel files. This tool is especially useful in environments where regular, structured reporting is required.\n",
    "\n",
    "### General Workflow of the Project\n",
    "\n",
    "1. **Database Connection**: First, a connection to the SQL Server database is established using server details, database name, and optional login credentials. This connection is managed via the SQLAlchemy library, which provides a powerful interface for interacting with SQL databases in Python.\n",
    "\n",
    "2. **Executing SQL Queries**: After establishing the connection, the user can execute their desired queries to retrieve data. These queries can involve selecting, filtering, and sorting data based on the needs of the user.\n",
    "\n",
    "3. **Data Display**: The retrieved data is displayed in a tabular format in the console. The number of rows to be displayed can be adjusted according to the user’s preference.\n",
    "\n",
    "4. **Saving Output to Excel Files**: A key feature of this project is the ability to save the extracted data into Excel files. Each dataset returned from the queries is saved in a new sheet within the same Excel file to prevent data overlap and ensure the reports are stored systematically.\n",
    "\n",
    "### Libraries and Modules Used\n",
    "\n",
    "- **Pandas**: Used to read and manage data in DataFrame format, as well as to export the data into Excel files.\n",
    "- **SQLAlchemy**: Manages database connections and query execution with the SQL Server.\n",
    "- **Openpyxl**: Facilitates working with Excel files, including creating and editing sheets within existing files.\n",
    "- **Pathlib**: Helps in managing file paths and ensuring files are correctly saved in the intended directory.\n",
    "- **Tabulate**: Provides a clean and organized display of data in a tabular format in the console.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This project serves as an efficient tool for users who need to generate and manage reports from SQL Server databases. By automating data extraction, processing, and saving the results into Excel files, the tool saves time and enhances the accuracy of data management.\n",
    "\n",
    "</section>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<section style=\"direction: rtl; text-align: justify; margin: 30px;\">\n",
    "\n",
    "### مقدمه پروژه\n",
    "\n",
    "این پروژه به منظور ایجاد یک ابزار برای دسترسی به پایگاه داده‌های SQL Server، اجرای کوئری‌های مختلف و استخراج داده‌ها طراحی شده است. هدف این پروژه، ارائه گزارش‌های جامع از داده‌های پایگاه داده به صورت خودکار و ذخیره آنها در قالب فایل‌های Excel است. این ابزار برای محیط‌هایی که نیاز به تولید گزارش‌های مکرر و طبقه‌بندی شده دارند، کاربرد دارد.\n",
    "\n",
    "### عملکرد کلی پروژه\n",
    "\n",
    "1. **اتصال به پایگاه داده**: ابتدا، با استفاده از اطلاعات مربوط به سرور SQL، پایگاه داده و در صورت نیاز اطلاعات ورود، اتصال به پایگاه داده برقرار می‌شود. این ارتباط از طریق کتابخانه SQLAlchemy مدیریت می‌شود که یک اینترفیس قدرتمند برای تعامل با پایگاه داده‌های SQL در پایتون است.\n",
    "  \n",
    "2. **اجرای کوئری‌های SQL**: پس از برقراری اتصال، کاربر می‌تواند کوئری‌های مورد نظر خود را برای استخراج داده‌ها اجرا کند. این کوئری‌ها می‌توانند شامل دستوراتی برای انتخاب، فیلتر کردن و طبقه‌بندی داده‌ها باشند.\n",
    "\n",
    "3. **نمایش داده‌ها**: داده‌های استخراج‌شده به صورت جدول در خروجی کنسول نمایش داده می‌شوند. تعداد سطرهایی که کاربر مایل به مشاهده آنهاست، می‌تواند به‌صورت دلخواه تنظیم شود.\n",
    "\n",
    "4. **ذخیره‌سازی خروجی‌ها در فایل‌های Excel**: یکی از ویژگی‌های اصلی این پروژه، امکان ذخیره داده‌های استخراج‌شده در فایل‌های Excel است. هر مجموعه داده‌ای که توسط کوئری‌ها بازگردانده شود، در یک شیت جدید از فایل اکسل ذخیره می‌شود تا از هم‌پوشانی و از دست رفتن داده‌ها جلوگیری شود.\n",
    "\n",
    "### کتابخانه‌ها و ماژول‌های مورد استفاده\n",
    "\n",
    "- **Pandas**: برای خواندن و مدیریت داده‌ها در قالب DataFrame و همچنین برای خروجی گرفتن از داده‌ها به فایل Excel استفاده می‌شود.\n",
    "- **SQLAlchemy**: برای برقراری ارتباط با پایگاه داده SQL Server و مدیریت کوئری‌ها به کار می‌رود.\n",
    "- **Openpyxl**: برای کار با فایل‌های Excel، از جمله ایجاد و ویرایش شیت‌ها در فایل‌های موجود.\n",
    "- **Pathlib**: برای مدیریت مسیرها و اطمینان از ذخیره درست فایل‌ها در دایرکتوری مورد نظر استفاده می‌شود.\n",
    "- **Tabulate**: برای نمایش داده‌ها به صورت جدولی و مرتب در خروجی کنسول استفاده می‌شود.\n",
    "\n",
    "### نتیجه‌گیری\n",
    "\n",
    "این پروژه ابزار مناسبی برای افرادی است که نیاز به تولید و مدیریت گزارش‌های داده‌ای از پایگاه داده‌های SQL Server دارند. با استفاده از این ابزار، داده‌ها به طور خودکار استخراج، پردازش و در فایل‌های اکسل ذخیره می‌شوند که باعث صرفه‌جویی در زمان و افزایش دقت در مدیریت داده‌ها می‌شود.\n",
    "\n",
    "</section>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calling the SQL Server Connection Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def create_connection(server, database, username=None, password=None):\n",
    "    \"\"\"\n",
    "    Create a connection to the SQL Server database using SQLAlchemy.\n",
    "    \n",
    "    Parameters:\n",
    "    - server: str, the name of the SQL Server\n",
    "    - database: str, the name of the database\n",
    "    - username: str, optional, SQL Server username (for SQL authentication)\n",
    "    - password: str, optional, SQL Server password (for SQL authentication)\n",
    "    \n",
    "    Returns:\n",
    "    - engine: sqlalchemy.engine.base.Engine, the SQLAlchemy engine object or None if the connection fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if username and password:\n",
    "            connection_string = f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "        else:\n",
    "            connection_string = f'mssql+pyodbc://{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "        \n",
    "        engine = create_engine(connection_string)\n",
    "        \n",
    "        # Test connection\n",
    "        with engine.connect() as conn:\n",
    "            logging.info(\"Connection successful!\")\n",
    "        \n",
    "        return engine\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        logging.error(f\"Connection failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 14:43:35,189 - INFO - Connection successful!\n",
      "2024-09-22 14:43:35,189 - INFO - Database connection established successfully.\n"
     ]
    }
   ],
   "source": [
    "def check_connection(engine):\n",
    "    \"\"\"\n",
    "    Check if the database connection is successful.\n",
    "    \n",
    "    Parameters:\n",
    "    - engine: sqlalchemy.engine.base.Engine, the SQLAlchemy engine object\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if connection is successful, False otherwise\n",
    "    \"\"\"\n",
    "    if engine:\n",
    "        logging.info(\"Database connection established successfully.\")\n",
    "        return True\n",
    "    else:\n",
    "        logging.error(\"Failed to establish database connection.\")\n",
    "        return False\n",
    "\n",
    "# Call the create_connection function\n",
    "server = r'imsalione-pc\\imsalionedb'\n",
    "database = 'pubs'\n",
    "\n",
    "engine = create_connection(server, database)\n",
    "\n",
    "# Use the check_connection function to verify the connection\n",
    "if check_connection(engine):\n",
    "    # Proceed with database operations\n",
    "    pass\n",
    "else:\n",
    "    # Handle the failed connection\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fetching and Displaying Data from SQL Server**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import exc\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the directory where you want to save the report files\n",
    "output_directory = Path(\"C:/Reports\")  # Adjust the path as needed\n",
    "output_directory.mkdir(parents=True, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "def fetch_and_display_data(engine, query, pnum=10, export_to_excel=False, export_to_csv=False):\n",
    "    \"\"\"\n",
    "    Fetch data from a SQL database and optionally export to Excel or CSV.\n",
    "    \n",
    "    Parameters:\n",
    "    - engine: SQLAlchemy engine object.\n",
    "    - query: SQL query string.\n",
    "    - pnum: int, number of rows to display (default is 10).\n",
    "    - export_to_excel: bool, whether to export data to an Excel file (default is False).\n",
    "    - export_to_csv: bool, whether to export data to a CSV file (default is False).\n",
    "    \"\"\"\n",
    "    \n",
    "    if engine:\n",
    "        try:\n",
    "            # Load data into a pandas DataFrame\n",
    "            df = pd.read_sql(query, engine)\n",
    "            \n",
    "            # Display the first pnum rows (or default 10 rows if pnum is not provided)\n",
    "            print(df.head(pnum).to_string(index=False))\n",
    "\n",
    "            # Export to Excel if requested\n",
    "            if export_to_excel:\n",
    "                file_path = output_directory / \"report.xlsx\"\n",
    "                new_sheet_name = f\"Rep_{pd.Timestamp.now().strftime('%d%m%Y%H%M%S')}\"\n",
    "                \n",
    "                try:\n",
    "                    with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='new') as writer:\n",
    "                        df.to_excel(writer, sheet_name=new_sheet_name, index=False)\n",
    "                        print(f\"Data exported to {file_path} in sheet {new_sheet_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error writing to existing Excel file: {e}\")\n",
    "            \n",
    "            # Export to CSV if requested\n",
    "            if export_to_csv:\n",
    "                csv_file_path = output_directory / f\"report_{pd.Timestamp.now().strftime('%d%m%Y%H%M%S')}.csv\"\n",
    "                try:\n",
    "                    df.to_csv(csv_file_path, index=False)\n",
    "                    print(f\"Data exported to CSV at {csv_file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error writing to CSV file: {e}\")\n",
    "\n",
    "        except exc.SQLAlchemyError as db_error:\n",
    "            print(f\"Database error occurred: {db_error}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    else:\n",
    "        print(\"No database connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing SQL Query to Fetch and Display Table Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE_CATALOG TABLE_SCHEMA  TABLE_NAME TABLE_TYPE\n",
      "         pubs          dbo sysdiagrams BASE TABLE\n",
      "         pubs          dbo     authors BASE TABLE\n",
      "         pubs          dbo  publishers BASE TABLE\n",
      "         pubs          dbo      titles BASE TABLE\n",
      "         pubs          dbo titleauthor BASE TABLE\n",
      "         pubs          dbo      stores BASE TABLE\n",
      "         pubs          dbo    roysched BASE TABLE\n",
      "         pubs          dbo   discounts BASE TABLE\n",
      "         pubs          dbo        jobs BASE TABLE\n",
      "         pubs          dbo    pub_info BASE TABLE\n",
      "Data exported to CSV at C:\\Reports\\report_22092024150618.csv\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM INFORMATION_SCHEMA.TABLES\"\n",
    "fetch_and_display_data(engine, query, pnum=10, export_to_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing SQL Query to Fetch and Display Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id stor_id  ord_num   ord_date  qty   payterms title_id\n",
      "  1    6380     6871 1994-09-14    5     Net 60   BU1032\n",
      "  2    6380     722a 1994-09-13    3     Net 60   PS2091\n",
      "  3    7066    A2976 1993-05-24   50     Net 30   PC8888\n",
      "  4    7066 QA7442.3 1994-09-13   75 ON invoice   PS2091\n",
      "  5    7067    D4482 1994-09-14   10     Net 60   PS2091\n",
      "  6    7067    P2121 1992-06-15   40     Net 30   TC3218\n",
      "  7    7067    P2121 1992-06-15   20     Net 30   TC4203\n",
      "  8    7067    P2121 1992-06-15   20     Net 30   TC7777\n",
      "  9    7131  N914008 1994-09-14   20     Net 30   PS2091\n",
      " 10    7131  N914014 1994-09-14   25     Net 30   MC3021\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM sales\"\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id stor_id  ord_num   ord_date  qty   payterms title_id SalesClass\n",
      "  1    6380     6871 1994-09-14    5     Net 60   BU1032    کم فروش\n",
      "  2    6380     722a 1994-09-13    3     Net 60   PS2091    کم فروش\n",
      "  3    7066    A2976 1993-05-24   50     Net 30   PC8888     پرفروش\n",
      "  4    7066 QA7442.3 1994-09-13   75 ON invoice   PS2091     پرفروش\n",
      "  5    7067    D4482 1994-09-14   10     Net 60   PS2091    کم فروش\n",
      "  6    7067    P2121 1992-06-15   40     Net 30   TC3218     پرفروش\n",
      "  7    7067    P2121 1992-06-15   20     Net 30   TC4203    کم فروش\n",
      "  8    7067    P2121 1992-06-15   20     Net 30   TC7777    کم فروش\n",
      "  9    7131  N914008 1994-09-14   20     Net 30   PS2091    کم فروش\n",
      " 10    7131  N914014 1994-09-14   25     Net 30   MC3021    کم فروش\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT *, CASE\n",
    "WHEN qty < 30 THEN N'کم فروش'\n",
    "WHEN qty >= 30 THEN N'پرفروش'\n",
    "END AS SalesClass \n",
    "FROM sales\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emp_id     fname minit     lname  job_id  job_lvl pub_id  hire_date  experience\n",
      "PMA42628M     Paolo     M   Accorti      13       35   0877 1992-08-27          32\n",
      "PSA89086M     Pedro     S    Afonso      14       89   1389 1990-12-24          34\n",
      "VPA30890F  Victoria     P  Ashworth       6      140   0877 1990-09-13          34\n",
      "H-B39728F     Helen         Bennett      12       35   0877 1989-09-21          35\n",
      "L-B31947F    Lesley           Brown       7      120   0877 1991-02-13          33\n",
      "F-C16315M Francisco           Chang       4      227   9952 1990-11-03          34\n",
      "PTC11962M    Philip     T    Cramer       2      215   9952 1989-11-11          35\n",
      "A-C71970F      Aria            Cruz      10       87   1389 1991-10-26          33\n",
      "AMD15433F       Ann     M     Devon       3      200   9952 1991-07-16          33\n",
      "ARD36773F   Anabela     R Domingues       8      100   0877 1993-01-27          31\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT * , DATEDIFF(YEAR, hire_date, GETDATE())\n",
    "                       AS experience \n",
    "                       FROM employee\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fname     lname  hire_date  experience experienceClass\n",
      "    Paolo   Accorti 1992-08-27          32              G1\n",
      "    Pedro    Afonso 1990-12-24          34              G1\n",
      " Victoria  Ashworth 1990-09-13          34              G1\n",
      "    Helen   Bennett 1989-09-21          35              G1\n",
      "   Lesley     Brown 1991-02-13          33              G1\n",
      "Francisco     Chang 1990-11-03          34              G1\n",
      "   Philip    Cramer 1989-11-11          35              G1\n",
      "     Aria      Cruz 1991-10-26          33              G1\n",
      "      Ann     Devon 1991-07-16          33              G1\n",
      "  Anabela Domingues 1993-01-27          31              G1\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT fname, lname, hire_date , DATEDIFF(YEAR, hire_date, GETDATE())\n",
    "                       AS experience, \n",
    "                       CASE \n",
    "                       WHEN DATEDIFF(YEAR, hire_date, GETDATE()) > 30 THEN 'G1'\n",
    "                       WHEN DATEDIFF(YEAR, hire_date, GETDATE()) <= 30 THEN 'G2'\n",
    "                       END AS experienceClass\n",
    "                       FROM employee\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id stor_id  ord_num   ord_date  qty   payterms title_id\n",
      "  1    6380     6871 1994-09-14    5     Net 60   BU1032\n",
      " 15    7896   QQ2299 1993-10-28   15     Net 60   BU7832\n",
      " 17    7896     X999 1993-02-21   35 ON invoice   BU2075\n",
      " 19    8042 423LL930 1994-09-14   10 ON invoice   BU1032\n",
      " 20    8042     P723 1993-03-11   25     Net 30   BU1111\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT * FROM sales\n",
    "WHERE title_id like 'B%'\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title         type  NewPrice\n",
      "                  The Psychology of Computer Cooking UNDECIDED         0.00\n",
      "                                       Net Etiquette popular_comp      0.00\n",
      "                               The Gourmet Microwave mod_cook          2.99\n",
      "                     You Can Combat Computer Stress! business          2.99\n",
      "                                   Life Without Fear psychology        7.00\n",
      "                 Emotional Security: A New Algorithm psychology        7.99\n",
      "                                 Is Anger the Enemy? psychology       10.95\n",
      "           Fifty Years in Buckingham Palace Kitchens trad_cook        11.95\n",
      "Cooking with Computers: Surreptitious Balance Sheets business         11.95\n",
      "                                      Sushi, Anyone? trad_cook        14.99\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT title, type, isnull(price, 0)\n",
    "AS NewPrice\n",
    "FROM TITLES\n",
    "ORDER BY NewPrice\"\"\"\n",
    "\n",
    "fetch_and_display_data(engine, query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
